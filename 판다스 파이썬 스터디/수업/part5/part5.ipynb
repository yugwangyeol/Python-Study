{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# deck 열의 NaN 개수 계산하기\n",
    "nan_deck = df['deck'].value_counts(dropna=False) \n",
    "print(nan_deck)\n",
    "\n",
    "# isnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().isnull())\n",
    "\n",
    "# notnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().notnull())\n",
    "\n",
    "# isnull() 메서드로 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# for 반복문으로 각 열의 NaN 개수 계산하기\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts()    # 각 열의 NaN 개수 파악\n",
    "\n",
    "    try: \n",
    "        print(col, ': ', missing_count[True])   # NaN 값이 있으면 개수를 출력\n",
    "    except:\n",
    "        print(col, ': ', 0)                     # NaN 값이 없으면 0개 출력\n",
    "        \n",
    "# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개 중 688개의 NaN 값)\n",
    "df_thresh = df.dropna(axis=1, thresh=500)  \n",
    "print(df_thresh.columns)\n",
    "\n",
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)  \n",
    "print(len(df_age))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값)\n",
    "print(df['age'].head(10))\n",
    "print('\\n')\n",
    "\n",
    "# age 열의 NaN값을 다른 나이 데이터의 평균으로 변경하기\n",
    "mean_age = df['age'].mean(axis=0)   # age 열의 평균 계산 (NaN 값 제외)\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값이 평균으로 대체)\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "# embark_town 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()   \n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# embark_town 열 829행의 NaN 데이터 출력 (NaN 값이 most_freq 값으로 대체)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "# embark_town 열의 NaN값을 바로 앞에 있는 828행의 값으로 변경하기\n",
    "df['embark_town'].fillna(method='ffill', inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],\n",
    "                  'c2':[1, 1, 1, 2, 2],\n",
    "                  'c3':[1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임 전체 행 데이터 중에서 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],\n",
    "                  'c2':[1, 1, 1, 2, 2],\n",
    "                  'c3':[1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임에서 중복 행을 제거\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)\n",
    "print('\\n')\n",
    "\n",
    "# c2, c3열을 기준으로 중복 행을 제거\n",
    "df3 = df.drop_duplicates(subset=['c2', 'c3'])\n",
    "print(df3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "print(df.head(3))    \n",
    "print('\\n')\n",
    "\n",
    "# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환 (mpg_to_kpl = 0.425)\n",
    "mpg_to_kpl = 1.60934 / 3.78541\n",
    "\n",
    "# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "print(df.head(3))    \n",
    "print('\\n')\n",
    "\n",
    "# kpl 열을 소수점 아래 둘째 자리에서 반올림 \n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head(3))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# 각 열의 자료형 확인\n",
    "print(df.dtypes)   \n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 고유값 확인\n",
    "print(df['horsepower'].unique())\n",
    "print('\\n')\n",
    "\n",
    "# 누락 데이터('?') 삭제 \n",
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 자료형 확인\n",
    "print(df['horsepower'].dtypes)  \n",
    "print('\\n')\n",
    "\n",
    "# origin 열의 고유값 확인\n",
    "print(df['origin'].unique())\n",
    "\n",
    "# 정수형 데이터를 문자형 데이터로 변환 \n",
    "df['origin'].replace({1:'USA', 2:'EU', 3:'JAPAN'}, inplace=True)\n",
    "\n",
    "# origin 열의 고유값과 자료형 확인\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes) \n",
    "print('\\n')\n",
    "\n",
    "# origin 열의 문자열 자료형을 범주형으로 변환\n",
    "df['origin'] = df['origin'].astype('category')     \n",
    "print(df['origin'].dtypes) \n",
    "\n",
    "# 범주형을 문자열로 다시 변환\n",
    "df['origin'] = df['origin'].astype('str')     \n",
    "print(df['origin'].dtypes)\n",
    "\n",
    "# model year 열의 정수형을 범주형으로 변환\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category') \n",
    "print(df['model year'].sample(3)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 함수로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers) \n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함 \n",
    "\n",
    "# horsepower 열, hp_bin 열의 첫 15행을 출력\n",
    "print(df[['horsepower', 'hp_bin']].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 으로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함\n",
    "\n",
    "# hp_bin 열의 범주형 데이터를 더미 변수로 변환\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 으로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함\n",
    "\n",
    "# sklern 라이브러리 불러오기\n",
    "from sklearn import preprocessing    \n",
    "\n",
    "# 전처리를 위한 encoder 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder()       # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder()   # one hot encoder 생성\n",
    "\n",
    "# label encoder로 문자열 범주를 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))  \n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))\n",
    "\n",
    "# 2차원 행렬로 형태 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1) \n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "\n",
    "# 희소행렬로 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name']  \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 통계 요약정보로 최대값(max)을 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "df.horsepower = df.horsepower / abs(df.horsepower.max()) \n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name']  \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 통계 요약정보로 최대값(max)과 최소값(min)을 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 CSV 파일을 가져와서 df로 변환\n",
    "df = pd.read_csv('stock-data.csv')\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "\n",
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "print(type(df['new_Date'][0]))\n",
    "\n",
    "# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정. 기존 날짜 열은 삭제\n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 형식의 문자열로 구성되는 리스트 정의\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "\n",
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "ts_dates = pd.to_datetime(dates)   \n",
    "print(ts_dates)\n",
    "print('\\n')\n",
    "\n",
    "# Timestamp를 Period로 변환\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)\n",
    "pr_month = ts_dates.to_period(freq='M')\n",
    "print(pr_month)\n",
    "pr_year = ts_dates.to_period(freq='A')\n",
    "print(pr_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp의 배열 만들기 - 월 간격, 월의 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01',    # 날짜 범위의 시작\n",
    "                   end=None,                 # 날짜 범위의 끝\n",
    "                   periods=6,                # 생성할 Timestamp의 개수\n",
    "                   freq='MS',                # 시간 간격 (MS: 월의 시작일)\n",
    "                   tz='Asia/Seoul')          # 시간대(timezone)\n",
    "print(ts_ms)\n",
    "print('\\n')\n",
    "\n",
    "# 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01', periods=6, \n",
    "                   freq='M',              # 시간 간격 (M: 월의 마지막 날)\n",
    "                   tz='Asia/Seoul')       # 시간대(timezone)\n",
    "print(ts_me)\n",
    "print('\\n')\n",
    "\n",
    "# 분기(3개월) 간격, 월의 마지막 날 기준\n",
    "ts_3m = pd.date_range('2019-01-01', periods=6, \n",
    "                   freq='3M',             # 시간 간격 (3M: 3개월)\n",
    "                   tz='Asia/Seoul')       # 시간대(timezone)\n",
    "print(ts_3m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='M')                   # 기간의 길이 (M: 월)\n",
    "print(pr_m)\n",
    "print('\\n')\n",
    "\n",
    "# Period 배열 만들기 - 1시간 길이\n",
    "pr_h = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='H')                   # 기간의 길이 (H: 시간)\n",
    "print(pr_h)\n",
    "print('\\n')\n",
    "\n",
    "# Period 배열 만들기 - 2시간 길이\n",
    "pr_2h = pd.period_range(start='2019-01-01',    # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='2H')                  # 기간의 길이 (H: 시간)\n",
    "print(pr_2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 파일 읽어와서 df로 변환\n",
    "df = pd.read_csv('stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# dt 속성을 이용하여 new_Date 열의 년월일 정보를 년, 월, 일로 구분\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# Timestamp를 Period로 변환하여 년월일 표기 변경하기\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 원하는 열을 새로운 행 인덱스로 지정\n",
    "df.set_index('Date_m', inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv() 함수로 파일 읽어와서 df로 변환\n",
    "df = pd.read_csv('stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   # 새로운 열에 추가\n",
    "df.set_index('new_Date', inplace=True)        # 행 인덱스로 지정\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.index)\n",
    "print('\\n')\n",
    "\n",
    "# 날짜 인덱스를 이용하여 데이터 선택하기\n",
    "df_y = df['2018']\n",
    "print(df_y.head())\n",
    "print('\\n')\n",
    "df_ym = df.loc['2018-07']    # loc 인덱서 활용\n",
    "print(df_ym)\n",
    "print('\\n')\n",
    "df_ym_cols = df.loc['2018-07', 'Start':'High']    # 열 범위 슬라이싱\n",
    "print(df_ym_cols)\n",
    "print('\\n')\n",
    "df_ymd = df['2018-07-02']\n",
    "print(df_ymd)\n",
    "print('\\n')\n",
    "df_ymd_range = df['2018-06-25':'2018-06-20']    # 날짜 범위 지정\n",
    "print(df_ymd_range)\n",
    "print('\\n')\n",
    "\n",
    "# 시간 간격 계산. 최근 180일 ~ 189일 사이의 값들만 선택하기\n",
    "today = pd.to_datetime('2018-12-25')            # 기준일 생성\n",
    "df['time_delta'] = today - df.index             # 날짜 차이 계산\n",
    "df.set_index('time_delta', inplace=True)        # 행 인덱스로 지정\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
